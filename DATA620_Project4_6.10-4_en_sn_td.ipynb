{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Informative Features \n",
    "\n",
    "## *Natural Language Processing in Python, Chapter 6.10 Exercise 3 and 4*\n",
    "\n",
    "> ### Bryant Chang, Thomas Detzel, Sandipayan Nandi, Erik Nylander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the required Libraries and setting a random seed.\n",
    "import nltk, random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import senseval\n",
    "random.seed(4568)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "### Instructions\n",
    "\n",
    "\n",
    "The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. It contains data for four words: hard, interest, line, and serve. Choose one of these four words, and load the corresponding data. Using this dataset, build a classifier that predicts the correct sense tag for a given instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Looking at the word \"interest\"\n",
    "First we choose the word 'interest' and load the corresponding data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instances = senseval.instances('interest.pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Examine individual contexts\n",
    "The contexts are clearly in the scope of finance and separate from the 'curiosity' meaning of 'interest'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "declines in        | interest  | rates .       -> interest_6\n",
      "indicate declining | interest  | rates because -> interest_6\n",
      "in short-term      | interest  | rates .       -> interest_6\n",
      "4 %                | interest  | in this       -> interest_5\n",
      "company with       | interests | in the        -> interest_5\n"
     ]
    }
   ],
   "source": [
    "for inst in instances[:5]:\n",
    "    p = inst.position\n",
    "    left = ' '.join(w for (w,t) in inst.context[p-2:p])\n",
    "    word = ' '.join(w for (w,t) in inst.context[p:p+1])\n",
    "    right = ' '.join(w for (w,t) in inst.context[p+1:p+3])\n",
    "    senses = ' '.join(inst.senses)\n",
    "    print('{:18s} | {:9s} | {:<13s} -> {}'.format(left, word, right, senses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Surrounding words using a feature set\n",
    "A good idea is too look at one or two words before and after each instance, one or two POSs before and after, as well as a bag of words. So we set up our feature extractor accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(instance):\n",
    "    feats = dict()\n",
    "    p = instance.position\n",
    "    # previous word & tag\n",
    "    if p: ## > 0\n",
    "        feats['wp'] = instance.context[p-1][0]\n",
    "        feats['tp'] = instance.context[p-1][1]\n",
    "    # bag of words if it's the first word\n",
    "    else: # \n",
    "        feats['wp'] = (p, 'BOW')\n",
    "        feats['tp'] = (p, 'BOW')\n",
    "    # following word & tag  \n",
    "        feats['wf'] = instance.context[p+1][0]\n",
    "        feats['tf'] = instance.context[p+1][1]\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our feature set, shuffle randomly for creating the training and test set later on, and split it into a training and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature set: 236 samples.\n",
      "Training set: 2132 samples.\n",
      "Test set: 236 samples.\n"
     ]
    }
   ],
   "source": [
    "featureset = [(features(i), i.senses[0]) \n",
    "              for i in instances \n",
    "              if len(i.senses)==1]\n",
    "\n",
    "random.shuffle(featureset)\n",
    "\n",
    "size = int(len(featureset) * 0.1)\n",
    "train_set, test_set = featureset[size:], featureset[:size]\n",
    "\n",
    "print('\\nFeature set: {} samples.'.format(size))\n",
    "print('Training set: {} samples.'.format(len(train_set)))\n",
    "print('Test set: {} samples.'.format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glimpse of feature dictionaries\n",
      "-------------------------------\n",
      "\n",
      "{'tp': 'JJR', 'wp': 'lower'}   -> interest_6\n",
      "{'tp': 'PRP$', 'wp': 'his'}    -> interest_1\n",
      "{'tp': 'VB', 'wp': 'pay'}      -> interest_6\n",
      "{'tp': 'JJ', 'wp': 'other'}    -> interest_3\n",
      "{'tp': 'JJ', 'wp': 'short-term'} -> interest_6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take a look\n",
    "print '\\nGlimpse of feature dictionaries'\n",
    "print '-------------------------------\\n'\n",
    "for i in xrange(5):\n",
    "    print('{:30s} -> {}'.format(featureset[i][0], featureset[i][1]))\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Naive Bayes Classifier\n",
    "The following code creates a Naive Bayes classifier using the training set and evaluates performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier1 = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 73.31%\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = nltk.classify.accuracy(classifier1, test_set)\n",
    "print('\\nAccuracy: {:.2%}'.format(accuracy1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decision Tree Classifier\n",
    "The following code creates a Decision Tree classifier and evaluate its performance with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier2 = nltk.DecisionTreeClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 70.76%.\n"
     ]
    }
   ],
   "source": [
    "accuracy2 = nltk.classify.accuracy(classifier2, test_set)\n",
    "print('\\nAccuracy: {:.2%}.'.format(accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "## Introduction and Results\n",
    "\n",
    "For this problem, we analyze the movie reviews corpus in NLTK using the document classifier from Chapter 6 section 10  of Natural Language Processing with Python to identify the 30 most informative features. See the discussion below for more, but results show that some of the words that tend to strongly associate with positive or negative reviews make semantic sense (mediocrity = negative, uplifting = positive), but that others can be misleading. In particular, names of actors and directors can be positive or negative features in films that are panned or praised, contributing to the roughly 30 percent error rate in our classifier. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Get documents, create classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a list containing each and is classification, either postive or negative. The list is shuffled in random order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Distribution of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are an equal number of positive and negative reviews in the list of 2,000 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive reviews = 1000\n",
      "Negative reviews = 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ''\n",
    "print 'Positive reviews = %s' % len(list((cat for (words, cat) in documents if cat=='pos')))\n",
    "print 'Negative reviews = %s' % len(list((cat for (words, cat) in documents if cat=='neg')))\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a document classifier using the 2,000 most common words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:2000] # [_document-classify-all-words]\n",
    "\n",
    "def document_features(document): # [_document-classify-extractor]\n",
    "    document_words = set(document) # [_document-classify-set]\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the feature extractor and a Naive Bayes classifier to classify the texts. The classifier has an accuracy rate of 71 percent. This means that in almost a third of cases, the classification is incorrect, although it's better than random chance (50-50, in this data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier accuracy is 69.00 percent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ''\n",
    "print 'Classifier accuracy is %.2f percent' % (100*nltk.classify.accuracy(classifier, test_set))\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Most informative features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the 30 most informative words for classifying a review as positive or negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(sans) = True              neg : pos    =      9.0 : 1.0\n",
      "    contains(mediocrity) = True              neg : pos    =      7.7 : 1.0\n",
      "     contains(dismissed) = True              pos : neg    =      7.0 : 1.0\n",
      "   contains(bruckheimer) = True              neg : pos    =      6.3 : 1.0\n",
      "   contains(overwhelmed) = True              pos : neg    =      6.3 : 1.0\n",
      "        contains(fabric) = True              pos : neg    =      6.3 : 1.0\n",
      "     contains(uplifting) = True              pos : neg    =      5.9 : 1.0\n",
      "         contains(patch) = True              neg : pos    =      5.8 : 1.0\n",
      "       contains(admired) = True              pos : neg    =      5.8 : 1.0\n",
      "        contains(doubts) = True              pos : neg    =      5.8 : 1.0\n",
      "          contains(wits) = True              pos : neg    =      5.7 : 1.0\n",
      "         contains(wires) = True              neg : pos    =      5.7 : 1.0\n",
      "           contains(ugh) = True              neg : pos    =      5.0 : 1.0\n",
      "       contains(topping) = True              pos : neg    =      5.0 : 1.0\n",
      "  contains(effortlessly) = True              pos : neg    =      5.0 : 1.0\n",
      "          contains(lang) = True              pos : neg    =      5.0 : 1.0\n",
      "          contains(hugo) = True              pos : neg    =      4.6 : 1.0\n",
      "         contains(tripe) = True              neg : pos    =      4.6 : 1.0\n",
      "   contains(understands) = True              pos : neg    =      4.4 : 1.0\n",
      "       contains(quicker) = True              neg : pos    =      4.3 : 1.0\n",
      "         contains(spins) = True              pos : neg    =      4.3 : 1.0\n",
      "        contains(benson) = True              pos : neg    =      4.3 : 1.0\n",
      "         contains(locks) = True              neg : pos    =      4.3 : 1.0\n",
      "          contains(wang) = True              pos : neg    =      4.3 : 1.0\n",
      "       contains(thieves) = True              neg : pos    =      4.2 : 1.0\n",
      "    contains(cronenberg) = True              pos : neg    =      4.2 : 1.0\n",
      "       contains(diverse) = True              pos : neg    =      3.9 : 1.0\n",
      "     contains(portrayed) = True              pos : neg    =      3.8 : 1.0\n",
      "      contains(attorney) = True              pos : neg    =      3.7 : 1.0\n",
      "   contains(interviewed) = True              neg : pos    =      3.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Positive Features\n",
    "*doubts, hugo, effortlessly, fabric, uplifiting, wits, topping, overwhelmed, sensational, lang, masquerading, matheson, spins, wang, understands, existential, reap, bandits*\n",
    "\n",
    "Many of the words associated with a positive review make sense. *Effortless, uplifiting, overwhelmed, topping, sensational, understands, existential,* and *reap* connote high quality. Words like *doubts, masquerading,* and *spins* suggest that the reveiwer was suprised by the quality. Proper names, such as *hugo, lang, and matheson*, suggest performance quality of individuals, but it's important to remember that the positive and negative categories apply to the movie -- actors and directors can have a positive performance even in a bad movie. Why does *bandits* associate with better movies? Of the six reviews that contain the word, only one is negative (a lame Disney remake)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of reviews containing 'bandits' = 6\n",
      "Number of negative reviews = 1\n",
      "Number of positive reviews = 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def filter_docs(doclist, value):\n",
    "    return filter(lambda d: value in d[0], doclist) \n",
    "\n",
    "bandits = filter_docs(documents, 'bandits')\n",
    "\n",
    "pos_count = len([cat for (words, cat) in bandits if cat == 'pos'])\n",
    "neg_count = len([cat for (words, cat) in bandits if cat == 'neg'])\n",
    "\n",
    "print ''\n",
    "print 'Number of reviews containing \\'bandits\\' = %r' % len(bandits)\n",
    "print 'Number of negative reviews = %r' % neg_count\n",
    "print 'Number of positive reviews = %r' % pos_count\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Negative Features\n",
    "\n",
    "*sans, bruckheimer, mediocrity, wires, ugh, tripe, quicker, maxwell, locks, dubious, interviewed, wcw*\n",
    "\n",
    "The negative classifiers are a shorter list. *Sans, mediocrity, ugh, tripe, quicker,* and *dubious* all clearly connote a bomb. *Bruckheimer*, refering to Jerry Bruckheimer is interesting in that he produces large-grossing films that are massivly popular. Some have received good reviews, but in this sample, only one of 10 Bruckheimer films won praise: \"Gone in 60 Seconds\", with Nicolas Cage, Robert Duvall and Angelina Jolie. (There are no 'bandits' mentioned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of reviews containing 'bruckheimer' = 10\n",
      "Number of negative reviews = 9\n",
      "Number of positive reviews = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bruckheimer = filter_docs(documents, 'bruckheimer')\n",
    "pos_count = len([cat for (words, cat) in bruckheimer if cat == 'pos'])\n",
    "neg_count = len([cat for (words, cat) in bruckheimer if cat == 'neg'])\n",
    "\n",
    "print ''\n",
    "print 'Number of reviews containing \\'bruckheimer\\' = %r' % len(bruckheimer)\n",
    "print 'Number of negative reviews = %r' % neg_count\n",
    "print 'Number of positive reviews = %r' % pos_count\n",
    "print ''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
